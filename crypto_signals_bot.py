import ccxt.async_support as ccxt
import pandas as pd
from ta.trend import IchimokuIndicator, MACD, ADXIndicator, PSARIndicator, VortexIndicator, CCIIndicator, EMAIndicator
from ta.volatility import BollingerBands, AverageTrueRange, KeltnerChannel, DonchianChannel
from ta.momentum import RSIIndicator, StochasticOscillator, WilliamsRIndicator, ROCIndicator
from ta.volume import OnBalanceVolumeIndicator, ChaikinMoneyFlowIndicator
import asyncio
import numpy as np
from datetime import datetime, timedelta
import logging
import os
import pickle
import json
from telegram import Bot
import aiofiles
import sys
import csv
import ta
import subprocess
import aiohttp
import openpyxl
from openpyxl.utils import get_column_letter
from scipy.stats import pearsonr
from scipy.signal import argrelextrema
import argparse
# Import the ML module
from ml_models import CryptoMLPredictor, batch_train_models, ohlcv_to_dataframe, ModelType
# Import pattern recognition module
from pattern_recognition import CandlestickPatterns, ChartPatterns, analyze_patterns
import joblib

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ SelectorEventLoop –¥–ª—è Windows
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s [%(levelname)s] %(message)s',
    level=logging.INFO,
    handlers=[
        logging.FileHandler('signals.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –¥–ª—è ccxt –∏ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
for name in logging.root.manager.loggerDict:
    if name.startswith('ccxt') or name in ['httpx', 'httpcore', 'urllib3', 'websockets', 'asyncio']:
        logging.getLogger(name).setLevel(logging.ERROR)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ ta
try:
    ta_version = ta.__version__
except AttributeError:
    try:
        ta_version = subprocess.check_output([sys.executable, '-m', 'pip', 'show', 'ta']).decode()
        ta_version = next((line.split(': ')[1] for line in ta_version.split('\n') if line.startswith('Version: ')), 'unknown')
    except Exception:
        ta_version = 'unknown'
logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–µ—Ä—Å–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ta: {ta_version}")
if ta_version < '0.11.0' and ta_version != 'unknown':
    logger.warning(f"–í–µ—Ä—Å–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ta ({ta_version}) —É—Å—Ç–∞—Ä–µ–ª–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–∏—Ç—å –¥–æ >=0.11.0: pip install ta --upgrade")

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
CONFIG_FILE = 'config.json'
DEFAULT_CONFIG = {
    'telegram_token': '8143467986:AAEo0IC1jwEpHXeNNIw1MmQORG-JPjU65nE',
    'telegram_chat_id': '-1002663850031',
    'cryptopanic_api_key': 'ac5c98562407cf9d569c4c453b02f5b2b50b79ae',
    'timeframe': '1h',
    'min_volume_usd': 1_000_000,
    'signal_threshold': 0.52,  # 12/23 –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
    'pump_price_threshold': 10.0,  # % —Ä–æ—Å—Ç–∞ –∑–∞ —á–∞—Å
    'pump_volume_multiplier': 3.0,  # Volume Spike
    'tp_percent': 5.0,  # %
    'sl_percent': 2.0,  # %
    'leverage': 10,
    'meme_coins': [
        "DOGE", "SHIB", "PEPE", "FLOKI", "WIF", "BONK", "BRETT", "BOME",
        "MEW", "MOG", "POPCAT", "QUBIC", "PEIPEI", "TURBO", "SUN", "NEIRO",
        "GME", "AMC", "SPX", "ZRO", "NOT", "RATS", "DOGS", "HMSTR"
    ],
    'meme_leverage': 5,
    'meme_tp_percent': 3.0,  # %
    'atr_volatility_multiplier': 1.0,  # –î–ª—è —Ñ–∏–ª—å—Ç—Ä–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
    'signal_expiry_hours': 12,
    'position_size_usd': 1000,
    'ohlcv_limit': 60,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –Ω–æ–≤—ã—Ö –ø–∞—Ä
    # ML parameters
    'use_ml_predictions': True,
    'ml_confidence_threshold': 0.65,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è —É—á—ë—Ç–∞ ML-–ø—Ä–æ–≥–Ω–æ–∑–∞
    'ml_retrain_days': 7,  # –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∫–∞–∂–¥—ã–µ 7 –¥–Ω–µ–π
    'min_ml_accuracy': 0.60,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å ML-–º–æ–¥–µ–ª–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
    # Pattern recognition parameters
    'use_pattern_recognition': True,
    'pattern_lookback_period': 100,  # Number of candles to look back for chart patterns
    'pattern_weight': 2.0,  # Weight for pattern signals (candlestick patterns + chart patterns)
    # Advanced ML settings
    'default_model_type': ModelType.RANDOM_FOREST  # Default ML model type to use
}

def load_config():
    try:
        with open(CONFIG_FILE, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        with open(CONFIG_FILE, 'w') as f:
            json.dump(DEFAULT_CONFIG, f, indent=4)
        return DEFAULT_CONFIG

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–æ–∫–æ–≤–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è ModelType –≤ –æ–±—ä–µ–∫—Ç ModelType
def convert_model_type(model_type_str):
    if isinstance(model_type_str, str):
        if model_type_str.lower() == "random_forest":
            return ModelType.RANDOM_FOREST
        elif model_type_str.lower() == "gradient_boosting":
            return ModelType.GRADIENT_BOOSTING
        elif model_type_str.lower() == "ensemble":
            return ModelType.ENSEMBLE
        elif model_type_str.lower() == "lstm":
            return ModelType.LSTM
    return ModelType.RANDOM_FOREST  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ

config = load_config()

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º model_type –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤ –æ–±—ä–µ–∫—Ç ModelType, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
if 'default_model_type' in config and isinstance(config['default_model_type'], str):
    config['default_model_type'] = convert_model_type(config['default_model_type'])

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Telegram –∏ CryptoPanic
TELEGRAM_TOKEN = config['telegram_token']
TELEGRAM_CHAT_ID = config['telegram_chat_id']
CRYPTOPANIC_API_KEY = config.get('cryptopanic_api_key', '')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Bybit
bybit = ccxt.bybit({
    'enableRateLimit': True,
    'defaultType': 'swap',
    'rateLimit': 100
})

# –¢–µ—Å—Ç Telegram –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
async def test_telegram():
    try:
        bot = Bot(token=TELEGRAM_TOKEN)
        await bot.send_message(chat_id=TELEGRAM_CHAT_ID, text="üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! –û–∂–∏–¥–∞—é —Å–∏–≥–Ω–∞–ª—ã...")
        logger.info("–¢–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram: {e}")

# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ –∫—ç—à–∞
def clean_old_cache(cache_dir='cache', max_age_hours=24):
    os.makedirs(cache_dir, exist_ok=True)
    now = datetime.now()
    for filename in os.listdir(cache_dir):
        file_path = os.path.join(cache_dir, filename)
        if os.path.isfile(file_path):
            file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
            if (now - file_mtime).total_seconds() > max_age_hours * 3600:
                os.remove(file_path)
                logger.debug(f"–£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π –∫—ç—à: {file_path}")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ä—ã–Ω–∫–æ–≤
async def load_markets():
    try:
        markets = await bybit.load_markets()
        symbols = [symbol for symbol, info in markets.items() if info['type'] == 'swap' and info['active'] and 
                  (symbol.endswith('/USDT:USDT') or symbol.endswith('/USDT')) and not 'BUSD' in symbol]
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º Bybit —Å–∏–º–≤–æ–ª—ã –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        standardized_symbols = [
            symbol.replace(':USDT', '') for symbol in symbols
        ]
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(standardized_symbols)} –∞–∫—Ç–∏–≤–Ω—ã—Ö USDT —Ñ—å—é—á–µ—Ä—Å–Ω—ã—Ö –ø–∞—Ä –Ω–∞ Bybit")
        return standardized_symbols
    except Exception as e:
        await send_telegram_message(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä—ã–Ω–∫–æ–≤ Bybit: {e}")
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä—ã–Ω–∫–æ–≤ Bybit: {e}")
        return []

# –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ OHLCV
async def load_ohlcv(symbol, timeframe=config['timeframe'], limit=config['ohlcv_limit']):
    cache_file = f'cache/{symbol.replace("/", "_")}_{timeframe}.pkl'
    os.makedirs('cache', exist_ok=True)
    
    try:
        if os.path.exists(cache_file):
            file_age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(cache_file))
            if file_age.total_seconds() < 3600:
                async with aiofiles.open(cache_file, 'rb') as f:
                    ohlcv = pickle.loads(await f.read())
                    logger.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω –∞–∫—Ç—É–∞–ª—å–Ω—ã–π –∫—ç—à –¥–ª—è {symbol}")
                    return ohlcv

        ohlcv = await bybit.fetch_ohlcv(symbol, timeframe, limit=limit)
        async with aiofiles.open(cache_file, 'wb') as f:
            await f.write(pickle.dumps(ohlcv))
        logger.debug(f"–û–±–Ω–æ–≤–ª—ë–Ω –∫—ç—à –¥–ª—è {symbol}")
        return ohlcv
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ OHLCV –¥–ª—è {symbol}: {e}")
        if os.path.exists(cache_file):
            async with aiofiles.open(cache_file, 'rb') as f:
                ohlcv = pickle.loads(await f.read())
                logger.warning(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –∫—ç—à –¥–ª—è {symbol} –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏")
                return ohlcv
        return None

# –ü–æ–ª—É—á–µ–Ω–∏–µ Fear & Greed Index
async def fetch_fear_and_greed():
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get('https://api.alternative.me/fng/') as response:
                data = await response.json()
                fng_value = int(data['data'][0]['value'])
                logger.debug(f"Fear & Greed Index: {fng_value}")
                return fng_value
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è Fear & Greed Index: {e}")
        return 50  # Fallback –∑–Ω–∞—á–µ–Ω–∏–µ

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ CryptoPanic
async def check_news(symbol, price_change_1h):
    if not CRYPTOPANIC_API_KEY or abs(price_change_1h) < 10:
        return "–ù–µ –ø—Ä–æ–≤–µ—Ä—è–ª–∏—Å—å"
    
    try:
        base_currency = symbol.split('/')[0].replace('1000', '').replace('10000', '').replace('1000000', '').replace('10000000', '')
        url = f"https://cryptopanic.com/api/v1/posts/?auth_token={CRYPTOPANIC_API_KEY}&currencies={base_currency}&filter=important,hot"
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                data = await response.json()
                if not data.get('results'):
                    return "–ù–µ –Ω–∞–π–¥–µ–Ω—ã"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
                recent_news = [
                    news for news in data['results']
                    if datetime.fromisoformat(news['published_at'].replace('Z', '+00:00')) > datetime.utcnow() - timedelta(hours=24)
                ]
                
                if not recent_news:
                    return "–ù–µ –Ω–∞–π–¥–µ–Ω—ã"
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–π –Ω–æ–≤–æ—Å—Ç–∏
                sentiment = recent_news[0].get('metadata', {}).get('sentiment', 'neutral')
                sentiment_str = "–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ" if sentiment == "positive" else "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ" if sentiment == "negative" else "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ"
                return f"{sentiment_str} (Œî—Ü–µ–Ω–∞ {price_change_1h:+.1f}%)"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è {symbol}: {e}")
        return "–ù–µ –ø—Ä–æ–≤–µ—Ä—è–ª–∏—Å—å"

# –§–∏–ª—å—Ç—Ä –ø–æ –æ–±—ä—ë–º—É —Ç–æ—Ä–≥–æ–≤ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
async def filter_high_volume_symbols(symbols, min_volume_usd=config['min_volume_usd']):
    cache_file = 'cache/high_volume_symbols.pkl'
    cache_max_age = 3600

    if os.path.exists(cache_file):
        file_age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(cache_file))
        if file_age.total_seconds() < cache_max_age:
            async with aiofiles.open(cache_file, 'rb') as f:
                cached_data = pickle.loads(await f.read())
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω –∫—ç—à —Ñ–∏–ª—å—Ç—Ä–∞ –æ–±—ä—ë–º–∞: {len(cached_data)} –ø–∞—Ä")
                return cached_data, {}

    high_volume_symbols = []
    volume_data = {}
    logger.info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è {len(symbols)} –ø–∞—Ä –ø–æ –æ–±—ä—ë–º—É >${min_volume_usd/1_000_000:.2f}M")
    
    async def check_volume(symbol):
        try:
            ticker = await bybit.fetch_ticker(symbol)
            volume_usd = ticker['baseVolume'] * ticker['close']
            
            # –ü–æ–¥—Ä–æ–±–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–º–æ–≤
            logger.info(f"–û–±—ä—ë–º –¥–ª—è {symbol}: ${volume_usd/1_000_000:.2f}M")
            
            if volume_usd > min_volume_usd:
                logger.debug(f"–ü–∞—Ä–∞ {symbol}: –û–±—ä—ë–º ${volume_usd/1_000_000:.2f}M (–ø—Ä–æ—à–ª–∞ —Ñ–∏–ª—å—Ç—Ä)")
                return symbol, volume_usd
            logger.debug(f"–ü–∞—Ä–∞ {symbol}: –û–±—ä—ë–º ${volume_usd/1_000_000:.2f}M (–æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–∞)")
            return None, None
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—ä—ë–º–∞ –¥–ª—è {symbol}: {e}")
            return None, None

    chunk_size = 5
    for i in range(0, len(symbols), chunk_size):
        chunk = symbols[i:i + chunk_size]
        results = await asyncio.gather(*[check_volume(symbol) for symbol in chunk])
        for symbol, volume_usd in results:
            if symbol:
                high_volume_symbols.append(symbol)
                volume_data[symbol] = volume_usd
        await asyncio.sleep(1)

    async with aiofiles.open(cache_file, 'wb') as f:
        await f.write(pickle.dumps(high_volume_symbols))
    
    logger.info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(high_volume_symbols)} –ø–∞—Ä –ø—Ä–æ—à–ª–∏ —Ñ–∏–ª—å—Ç—Ä –æ–±—ä—ë–º–∞")
    return high_volume_symbols, volume_data

# –†–∞—Å—á—ë—Ç VWAP
def calculate_vwap(df, sigma=1.0):
    try:
        typical_price = (df['high'] + df['low'] + df['close']) / 3
        vwap = (typical_price * df['volume']).cumsum() / df['volume'].cumsum()
        vwap_dev = typical_price.rolling(window=20).std()
        return vwap, vwap_dev * sigma
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ VWAP: {e}")

# –†–∞—Å—á—ë—Ç —É—Ä–æ–≤–Ω–µ–π –§–∏–±–æ–Ω–∞—á—á–∏
def calculate_fibonacci_levels(df, period=20):
    try:
        high = df['high'].rolling(window=period).max()
        low = df['low'].rolling(window=period).min()
        diff = high - low
        fib_382 = low + diff * 0.382
        fib_618 = low + diff * 0.618
        return fib_382, fib_618
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ —É—Ä–æ–≤–Ω–µ–π –§–∏–±–æ–Ω–∞—á—á–∏: {e}")
        return pd.Series(np.nan, index=df.index), pd.Series(np.nan, index=df.index)

# –≠–∫—Å–ø–æ—Ä—Ç CSV –≤ Excel
def export_csv_to_excel(csv_file='signals_history.csv', excel_file='signals_history.xlsx'):
    try:
        # –ß—Ç–µ–Ω–∏–µ CSV —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
        df = pd.read_csv(csv_file, encoding='utf-8-sig')
        df.to_excel(excel_file, index=False, engine='openpyxl')
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤
        wb = openpyxl.load_workbook(excel_file)
        ws = wb.active
        for col in ws.columns:
            max_length = 0
            column = col[0].column_letter
            for cell in col:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = (max_length + 2)
            ws.column_dimensions[column].width = adjusted_width
        wb.save(excel_file)
        
        logger.debug(f"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ Excel: {excel_file}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Excel: {e}")
        # –ü–æ–ø—ã—Ç–∫–∞ —Å –¥—Ä—É–≥–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π –ø—Ä–∏ –æ—à–∏–±–∫–µ
        try:
            df = pd.read_csv(csv_file, encoding='latin1')
            df.to_excel(excel_file, index=False, engine='openpyxl')
            logger.debug(f"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ Excel —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π latin1: {excel_file}")
        except Exception as e2:
            logger.error(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ Excel: {e2}")

# –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –∏—Å—Ö–æ–¥–∞–º
def generate_analytics():
    try:
        df = pd.read_csv('signals_history.csv')
        if df.empty:
            return "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–∏–≥–Ω–∞–ª–∞—Ö."

        # –ü–∞—Ä—Å–∏–Ω–≥ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        df['indicators'] = df['indicators'].apply(lambda x: eval(x) if isinstance(x, str) else x)

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_signals = len(df)
        tp_count = len(df[df['outcome'] == 'TP'])
        sl_count = len(df[df['outcome'] == 'SL'])
        expired_count = len(df[df['outcome'] == 'Expired'])
        win_rate = (tp_count / total_signals * 100) if total_signals > 0 else 0
        avg_pl_percent = df['profit_loss_percent'].mean()
        avg_pl_usd = df['profit_loss_usd'].mean()

        analytics = f"üìä –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ ({total_signals}):\n"
        analytics += f"  TP: {tp_count} ({tp_count/total_signals*100:.1f}%)\n"
        analytics += f"  SL: {sl_count} ({sl_count/total_signals*100:.1f}%)\n"
        analytics += f"  Expired: {expired_count} ({expired_count/total_signals*100:.1f}%)\n"
        analytics += f"  –û–±—â–∏–π –≤–∏–Ω—Ä–µ–π—Ç: {win_rate:.1f}%\n"
        analytics += f"  –°—Ä–µ–¥–Ω–∏–π P/L: {avg_pl_percent:+.2f}% (${avg_pl_usd:+.2f})\n"

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ä–∞–º
        analytics += "\nüîç –ü–æ –ø–∞—Ä–∞–º:\n"
        for symbol in df['symbol'].unique():
            symbol_df = df[df['symbol'] == symbol]
            symbol_signals = len(symbol_df)
            symbol_tp = len(symbol_df[symbol_df['outcome'] == 'TP'])
            symbol_win_rate = (symbol_tp / symbol_signals * 100) if symbol_signals > 0 else 0
            symbol_avg_pl = symbol_df['profit_loss_percent'].mean()
            analytics += f"  {symbol}: {symbol_signals} —Å–∏–≥–Ω–∞–ª–æ–≤, {symbol_win_rate:.1f}% TP, —Å—Ä–µ–¥–Ω–∏–π P/L {symbol_avg_pl:+.2f}%\n"

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Å–∏–≥–Ω–∞–ª–æ–≤
        analytics += "\nüìà –ü–æ —Ç–∏–ø–∞–º:\n"
        for signal_type in ['long', 'short']:
            type_df = df[df['type'] == signal_type]
            type_signals = len(type_df)
            type_tp = len(type_df[type_df['outcome'] == 'TP'])
            type_win_rate = (type_tp / type_signals * 100) if type_signals > 0 else 0
            type_avg_pl = type_df['profit_loss_percent'].mean()
            analytics += f"  {signal_type.capitalize()}: {type_signals} —Å–∏–≥–Ω–∞–ª–æ–≤, {type_win_rate:.1f}% TP, —Å—Ä–µ–¥–Ω–∏–π P/L {type_avg_pl:+.2f}%\n"

        # –í–∏–Ω—Ä–µ–π—Ç –ø–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º
        analytics += "\nüîß –í–∏–Ω—Ä–µ–π—Ç –ø–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º:\n"
        indicator_names = {
            'price_above_cloud': 'Ichimoku Cloud',
            'price_below_cloud': 'Ichimoku Cloud',
            'macd_above_signal': 'MACD Above Signal',
            'macd_below_signal': 'MACD Below Signal',
            'rsi_oversold': 'RSI Oversold',
            'rsi_overbought': 'RSI Overbought',
            'price_below_bb_lower': 'Bollinger Bands Lower',
            'price_above_bb_upper': 'Bollinger Bands Upper',
            'ema_crossover_long': 'EMA Crossover',
            'ema_crossover_short': 'EMA Crossover',
            'stoch_oversold': 'Stochastic Oversold',
            'stoch_overbought': 'Stochastic Overbought',
            'obv_uptrend': 'OBV Uptrend',
            'obv_downtrend': 'OBV Downtrend',
            'parabolic_sar_long': 'Parabolic SAR',
            'parabolic_sar_short': 'Parabolic SAR',
            'adx_strong_trend': 'ADX Strong Trend',
            'volume_spike': 'Volume Spike',
            'rsi_divergence_bullish': 'RSI Bullish Divergence',
            'rsi_divergence_bearish': 'RSI Bearish Divergence',
            'price_above_vwap': 'Price Above VWAP',
            'price_below_vwap': 'Price Below VWAP',
            'cci_oversold': 'CCI Oversold',
            'cci_overbought': 'CCI Overbought',
            'williams_r_oversold': 'Williams %R Oversold',
            'williams_r_overbought': 'Williams %R Overbought',
            'fibonacci_382_long': 'Fibonacci 38.2% Long',
            'fibonacci_382_short': 'Fibonacci 38.2% Short',
            'vortex_long': 'Vortex Long',
            'vortex_short': 'Vortex Short',
            'cmf_long': 'Chaikin Money Flow Long',
            'cmf_short': 'Chaikin Money Flow Short',
            'keltner_long': 'Keltner Channel Long',
            'keltner_short': 'Keltner Channel Short',
            'roc_long': 'Rate of Change Long',
            'roc_short': 'Rate of Change Short',
            'donchian_long': 'Donchian Channel Long',
            'donchian_short': 'Donchian Channel Long',
            'fng_fear': 'Fear & Greed Fear',
            'fng_greed': 'Fear & Greed Greed'
        }
        indicator_stats = {}
        for ind in df['indicators'].iloc[0].keys():
            ind_signals = len(df[df['indicators'].apply(lambda x: x.get(ind))])
            ind_tp = len(df[(df['indicators'].apply(lambda x: x.get(ind))) & (df['outcome'] == 'TP')])
            ind_win_rate = (ind_tp / ind_signals * 100) if ind_signals > 0 else 0
            if ind_signals >= 5:  # –ú–∏–Ω–∏–º—É–º 5 —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                indicator_stats[ind] = (ind_win_rate, ind_signals)
        sorted_indicators = sorted(indicator_stats.items(), key=lambda x: x[1][0], reverse=True)
        for ind, (win_rate, signals) in sorted_indicators[:10]:  # –¢–æ–ø-10 –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            analytics += f"  {indicator_names.get(ind, ind)}: {win_rate:.1f}% ({signals} —Å–∏–≥–Ω–∞–ª–æ–≤)\n"

        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å P/L
        analytics += "\nüìâ –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å P/L:\n"
        if len(df) >= 10:  # –ú–∏–Ω–∏–º—É–º 10 —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            correlations = {}
            for ind in df['indicators'].iloc[0].keys():
                ind_values = df['indicators'].apply(lambda x: 1 if x.get(ind) else 0)
                if ind_values.sum() > 0:  # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∞–∫—Ç–∏–≤–µ–Ω —Ö–æ—Ç—è –±—ã —Ä–∞–∑
                    corr, _ = pearsonr(ind_values, df['profit_loss_percent'])
                    if not np.isnan(corr):
                        correlations[ind] = corr
            sorted_correlations = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)
            for ind, corr in sorted_correlations[:5]:  # –¢–æ–ø-5 –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
                analytics += f"  {indicator_names.get(ind, ind)}: {corr:+.2f}\n"
        else:
            analytics += "  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏.\n"

        # –ó–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª
        with open('analytics_report.txt', 'w') as f:
            f.write(analytics)

        # –≠–∫—Å–ø–æ—Ä—Ç –≤ Excel
        analytics_df = pd.DataFrame({
            'Metric': [],
            'Value': []
        })
        for line in analytics.split('\n'):
            if ':' in line:
                metric, value = line.split(':', 1)
                analytics_df = pd.concat([analytics_df, pd.DataFrame({'Metric': [metric.strip()], 'Value': [value.strip()]})], ignore_index=True)
        analytics_df.to_excel('analytics_report.xlsx', index=False, engine='openpyxl')
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤
        wb = openpyxl.load_workbook('analytics_report.xlsx')
        ws = wb.active
        for col in ws.columns:
            max_length = 0
            column = col[0].column_letter
            for cell in col:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = (max_length + 2)
            ws.column_dimensions[column].width = adjusted_width
        wb.save('analytics_report.xlsx')
        
        logger.info("–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞")
        return analytics
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}"

# –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram
async def send_telegram_message(message):
    try:
        bot = Bot(token=TELEGRAM_TOKEN)
        await bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=message)
        logger.info(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram: {message[:100]}...")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")

# –ó–∞–ø–∏—Å—å —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ CSV
def log_signal_to_csv(signal):
    """–ó–∞–ø–∏—Å—å —Å–∏–≥–Ω–∞–ª–∞ –≤ CSV-—Ñ–∞–π–ª"""
    file_exists = os.path.isfile('signals_history.csv')
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è CSV
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    symbol = signal['symbol']
    signal_type = signal['type']
    entry_price = signal['entry_price']
    tp = signal['tp']
    sl = signal['sl']
    leverage = signal['leverage']
    
    # ML prediction data
    ml_prediction = signal.get('ml_prediction')
    ml_direction = ml_prediction['direction'] if ml_prediction else 'none'
    ml_confidence = ml_prediction['confidence'] if ml_prediction else 0
    
    # Indicators summary
    total_indicators = len(signal['indicators'])
    positive_indicators = sum(1 for v in signal['indicators'].values() if v)
    
    # High confidence combos
    high_confidence = ','.join(signal['high_confidence_combo']) if signal['high_confidence_combo'] else 'none'
    
    # CSV fields
    fields = [
        now,                   # Timestamp
        symbol,                # Symbol
        signal_type,           # Signal type (long/short)
        entry_price,           # Entry price
        tp,                    # Take profit
        sl,                    # Stop loss
        leverage,              # Leverage
        signal['volume_usd'],  # Volume USD
        signal['news'],        # News context
        'active',              # Status (active/tp/sl/expired)
        None,                  # Exit price (filled when closed)
        None,                  # P/L % (filled when closed)
        None,                  # P/L $ (filled when closed)
        None,                  # Exit time (filled when closed)
        positive_indicators,   # Number of positive indicators
        total_indicators,      # Total indicators
        high_confidence,       # High confidence combination
        ml_direction,          # ML prediction direction
        ml_confidence          # ML prediction confidence
    ]
    
    try:
        with open('signals_history.csv', 'a', newline='') as f:
            writer = csv.writer(f)
            
            # Write header if file doesn't exist
            if not file_exists:
                writer.writerow([
                    'timestamp', 'symbol', 'type', 'entry_price', 'tp', 'sl', 'leverage',
                    'volume_usd', 'news', 'status', 'exit_price', 'pl_percent', 'pl_usd', 'exit_time',
                    'positive_indicators', 'total_indicators', 'high_confidence', 
                    'ml_direction', 'ml_confidence'
                ])
            
            writer.writerow(fields)
            logger.debug(f"–°–∏–≥–Ω–∞–ª {symbol} {signal_type} –∑–∞–ø–∏—Å–∞–Ω –≤ CSV")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Å–∏–≥–Ω–∞–ª–∞ –≤ CSV: {e}")

    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Excel –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–∏
    asyncio.create_task(update_excel())

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞ –≤ CSV
def update_signal_in_csv(signal):
    csv_file = 'signals_history.csv'
    temp_file = 'signals_history_temp.csv'
    found = False

    with open(csv_file, 'r') as f, open(temp_file, 'w', newline='') as temp:
        reader = csv.reader(f)
        writer = csv.writer(temp)
        header = next(reader)
        writer.writerow(header)

        for row in reader:
            if (row[0] == signal['timestamp'] and
                row[1] == signal['symbol'] and
                row[2] == signal['type']):
                writer.writerow([
                    signal['timestamp'],
                    signal['symbol'],
                    signal['type'],
                    signal['entry'],
                    signal['tp'],
                    signal['sl'],
                    signal['leverage'],
                    str(signal['indicators']),
                    signal.get('exit_price', ''),
                    signal.get('outcome', ''),
                    signal.get('profit_loss_percent', ''),
                    signal.get('profit_loss_usd', ''),
                    signal.get('exit_timestamp', '')
                ])
                found = True
            else:
                writer.writerow(row)

    if found:
        os.replace(temp_file, csv_file)
        logger.debug(f"–û–±–Ω–æ–≤–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å –≤ CSV –¥–ª—è {signal['symbol']}")
        export_csv_to_excel()
    else:
        logger.warning(f"–°–∏–≥–Ω–∞–ª {signal['symbol']} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ CSV –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")
        os.remove(temp_file)

# –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –∏—Å—Ö–æ–¥–µ
async def send_outcome_notification(signal):
    try:
        signal_type = "–ü–æ–∫—É–ø–∫–∞" if signal['type'] == 'long' else "–ü—Ä–æ–¥–∞–∂–∞"
        message = f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∏–≥–Ω–∞–ª–∞: {signal_type} {signal['symbol']}\n"
        message += f"üí∞ –í—Ö–æ–¥: ${signal['entry']:.4f}\n"
        message += f"üìâ –í—ã—Ö–æ–¥: ${signal['exit_price']:.4f}\n"
        message += f"üîî –ò—Å—Ö–æ–¥: {signal['outcome']}\n"
        message += f"üìà P/L: {signal['profit_loss_percent']:+.2f}% (${signal['profit_loss_usd']:+.2f})\n"
        message += f"üïí –í—Ä–µ–º—è –∑–∞–∫—Ä—ã—Ç–∏—è: {signal['exit_timestamp']}\n"
        message += f"‚ö†Ô∏è –ù–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è!"
        
        await send_telegram_message(message)
        logger.info(f"–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –∏—Å—Ö–æ–¥–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {signal['type']} –Ω–∞ {signal['symbol']}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –∏—Å—Ö–æ–¥–µ: {e}")

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å—Ö–æ–¥–∞ —Å–∏–≥–Ω–∞–ª–∞
async def monitor_signal_outcome(signal, expiry_hours=config['signal_expiry_hours']):
    try:
        symbol = signal['symbol']
        signal_type = signal['type']
        entry_price = signal['entry']
        tp = signal['tp']
        sl = signal['sl']
        leverage = signal['leverage']
        position_size = config['position_size_usd']
        start_time = pd.to_datetime(signal['timestamp'])
        expiry_time = start_time + timedelta(hours=expiry_hours)

        logger.debug(f"–ù–∞—á–∞–ª–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å–∏–≥–Ω–∞–ª–∞: {signal_type} –Ω–∞ {symbol}")

        while datetime.utcnow() < expiry_time:
            try:
                ticker = await bybit.fetch_ticker(symbol)
                current_price = ticker['last']
                logger.debug(f"{symbol}: –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞ ${current_price:.4f}")

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ TP/SL
                if signal_type == 'long':
                    if current_price >= tp:
                        outcome = 'TP'
                        exit_price = tp
                        profit_loss_percent = (tp - entry_price) / entry_price * 100 * leverage
                        profit_loss_usd = position_size * (tp / entry_price - 1) * leverage
                        break
                    elif current_price <= sl:
                        outcome = 'SL'
                        exit_price = sl
                        profit_loss_percent = (sl - entry_price) / entry_price * 100 * leverage
                        profit_loss_usd = position_size * (sl / entry_price - leverage)
                        break
                else:  # short
                    if current_price <= tp:
                        outcome = 'TP'
                        exit_price = tp
                        profit_loss_percent = (entry_price - tp) / entry_price * 100 * leverage
                        profit_loss_usd = position_size * (entry_price / tp - 1) * leverage
                        break
                    elif current_price >= sl:
                        outcome = 'SL'
                        exit_price = sl
                        profit_loss_percent = (entry_price - sl) / entry_price * 100 * leverage
                        profit_loss_usd = position_size * (entry_price / sl - 1) * leverage
                        break

                await asyncio.sleep(7200)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 2 —á–∞—Å–∞
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ {symbol}: {e}")
                await asyncio.sleep(300)  # –ü–∞—É–∑–∞ 5 –º–∏–Ω—É—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ

        else:
            # –°–∏–≥–Ω–∞–ª –∏—Å—Ç—ë–∫
            outcome = 'Expired'
            exit_price = current_price
            profit_loss_percent = 0
            profit_loss_usd = 0

        exit_timestamp = datetime.utcnow().isoformat() + 'Z'
        signal.update({
            'exit_price': exit_price,
            'outcome': outcome,
            'profit_loss_percent': profit_loss_percent,
            'profit_loss_usd': profit_loss_usd,
            'exit_timestamp': exit_timestamp
        })

        logger.info(f"–°–∏–≥–Ω–∞–ª {signal_type} –Ω–∞ {symbol}: –ò—Å—Ö–æ–¥ = {outcome}, P/L = {profit_loss_percent:.2f}% (${profit_loss_usd:.2f})")

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ CSV –∏ —ç–∫—Å–ø–æ—Ä—Ç –≤ Excel
        update_signal_in_csv(signal)

        # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ–± –∏—Å—Ö–æ–¥–µ
        await send_outcome_notification(signal)

        return signal
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏—Å—Ö–æ–¥–∞ –¥–ª—è {symbol}: {e}")
        return None

# –†–∞—Å—á—ë—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
def calculate_indicators(df, fng_value):
    """–†–∞—Å—á—ë—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    try:
        if len(df) < 14:
            return None
            
        df = df.copy()
        
        # –†–∞—Å—á—ë—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        current_price = df['close'].iloc[-1]
        
        # RSI
        rsi = RSIIndicator(close=df['close'], window=14)
        df['rsi'] = rsi.rsi()
        
        # MACD
        macd = MACD(close=df['close'])
        df['macd'] = macd.macd()
        df['macd_signal'] = macd.macd_signal()
        df['macd_diff'] = macd.macd_diff()
        
        # Bollinger Bands
        bb = BollingerBands(close=df['close'], window=20, window_dev=2)
        df['bb_upper'] = bb.bollinger_hband()
        df['bb_lower'] = bb.bollinger_lband()
        df['bb_middle'] = bb.bollinger_mavg()
        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']
        
        # ATR (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏)
        atr = AverageTrueRange(high=df['high'], low=df['low'], close=df['close'], window=14)
        df['atr'] = atr.average_true_range()
        df['avg_atr'] = df['atr'].rolling(window=14).mean()
        
        # EMA
        df['ema_9'] = ta.trend.ema_indicator(df['close'], window=9)
        df['ema_21'] = ta.trend.ema_indicator(df['close'], window=21)
        df['ema_50'] = ta.trend.ema_indicator(df['close'], window=50)
        df['ema_200'] = ta.trend.ema_indicator(df['close'], window=200)
        
        # Stochastic
        stoch = StochasticOscillator(high=df['high'], low=df['low'], close=df['close'])
        df['stoch_k'] = stoch.stoch()
        df['stoch_d'] = stoch.stoch_signal()
        
        # ADX
        adx = ADXIndicator(high=df['high'], low=df['low'], close=df['close'])
        df['adx'] = adx.adx()
        df['adx_plus_di'] = adx.adx_pos()
        df['adx_minus_di'] = adx.adx_neg()
        
        # OBV
        obv = OnBalanceVolumeIndicator(close=df['close'], volume=df['volume'])
        df['obv'] = obv.on_balance_volume()
        df['obv_ema'] = ta.trend.ema_indicator(df['obv'], window=21)
        
        # Ichimoku
        ichimoku = IchimokuIndicator(high=df['high'], low=df['low'])
        df['tenkan_sen'] = ichimoku.ichimoku_conversion_line()
        df['kijun_sen'] = ichimoku.ichimoku_base_line()
        df['senkou_span_a'] = ichimoku.ichimoku_a()
        df['senkou_span_b'] = ichimoku.ichimoku_b()
        
        # Parabolic SAR
        psar = PSARIndicator(high=df['high'], low=df['low'], close=df['close'])
        df['psar'] = psar.psar()
        
        # Williams %R
        wr = WilliamsRIndicator(high=df['high'], low=df['low'], close=df['close'])
        df['wr'] = wr.williams_r()
        
        # Supertrend
        atr_period = config.get('supertrend_atr_period', 14)
        multiplier = config.get('supertrend_multiplier', 3.0)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—á–∏—Ç–∞–Ω–Ω—ã–π —Ä–∞–Ω–µ–µ ATR –¥–ª—è —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥–∞
        df['basic_upper'] = (df['high'] + df['low']) / 2 + multiplier * df['atr']
        df['basic_lower'] = (df['high'] + df['low']) / 2 - multiplier * df['atr']
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥–∞
        df['supertrend'] = 0.0
        df['supertrend_direction'] = 0  # 1 –¥–ª—è –±—ã—á—å–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞, -1 –¥–ª—è –º–µ–¥–≤–µ–∂—å–µ–≥–æ
        
        # –ü–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥–∞
        if len(df) > atr_period:
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            df.loc[atr_period, 'supertrend'] = df.loc[atr_period, 'basic_upper']
            df.loc[atr_period, 'supertrend_direction'] = -1  # –ù–∞—á–∏–Ω–∞–µ–º —Å –º–µ–¥–≤–µ–∂—å–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥ –¥–ª—è –∫–∞–∂–¥–æ–π —Å–≤–µ—á–∏
            for i in range(atr_period + 1, len(df)):
                prev_supertrend = df.loc[i-1, 'supertrend']
                prev_direction = df.loc[i-1, 'supertrend_direction']
                curr_close = df.loc[i, 'close']
                curr_upper = df.loc[i, 'basic_upper']
                curr_lower = df.loc[i, 'basic_lower']
                
                # –õ–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥–∞
                if prev_supertrend == prev_supertrend:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
                    if prev_supertrend <= df.loc[i-1, 'close'] and prev_direction <= 0:
                        # –ü–µ—Ä–µ—Ö–æ–¥ –∫ –±—ã—á—å–µ–º—É —Ç—Ä–µ–Ω–¥—É
                        df.loc[i, 'supertrend'] = curr_lower
                        df.loc[i, 'supertrend_direction'] = 1
                    elif prev_supertrend > df.loc[i-1, 'close'] and prev_direction >= 0:
                        # –ü–µ—Ä–µ—Ö–æ–¥ –∫ –º–µ–¥–≤–µ–∂—å–µ–º—É —Ç—Ä–µ–Ω–¥—É
                        df.loc[i, 'supertrend'] = curr_upper
                        df.loc[i, 'supertrend_direction'] = -1
                    elif prev_direction == 1:
                        # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –±—ã—á—å–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞
                        df.loc[i, 'supertrend'] = max(curr_lower, prev_supertrend)
                        df.loc[i, 'supertrend_direction'] = 1
                    else:
                        # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –º–µ–¥–≤–µ–∂—å–µ–≥–æ —Ç—Ä–µ–Ω–¥–∞
                        df.loc[i, 'supertrend'] = min(curr_upper, prev_supertrend)
                        df.loc[i, 'supertrend_direction'] = -1
                else:
                    # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ NaN, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    df.loc[i, 'supertrend'] = curr_upper
                    df.loc[i, 'supertrend_direction'] = -1
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å—á–µ—Ç–∞ –°—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥–∞
            supertrend_value = df['supertrend'].iloc[-1]
            supertrend_direction = df['supertrend_direction'].iloc[-1]
            current_close = df['close'].iloc[-1]
            
            supertrend_long = current_close > supertrend_value
            supertrend_short = current_close < supertrend_value
            
            logger.debug(f"Supertrend: –∑–Ω–∞—á–µ–Ω–∏–µ={supertrend_value:.6f}, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ={'UP' if supertrend_direction > 0 else 'DOWN'}")
            logger.debug(f"Supertrend —Å–∏–≥–Ω–∞–ª—ã: Long={supertrend_long}, Short={supertrend_short}, —Ç–µ–∫—É—â–∞—è —Ü–µ–Ω–∞={current_close:.6f}")
            
            if supertrend_long:
                logger.debug(f"–¶–µ–Ω–∞ –≤—ã—à–µ Supertrend –Ω–∞ {((current_close - supertrend_value) / supertrend_value * 100):.2f}%")
            elif supertrend_short:
                logger.debug(f"–¶–µ–Ω–∞ –Ω–∏–∂–µ Supertrend –Ω–∞ {((supertrend_value - current_close) / supertrend_value * 100):.2f}%")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –∏ —É—Å–ª–æ–≤–∏–π
        indicators = {
            'current_price': current_price,
            'rsi': df['rsi'].iloc[-1],
            'macd': df['macd'].iloc[-1],
            'macd_signal': df['macd_signal'].iloc[-1],
            'bb_width': df['bb_width'].iloc[-1],
            'atr': df['atr'].iloc[-1],
            'avg_atr': df['avg_atr'].iloc[-1],
            'fng_value': fng_value,
            
            # –£—Å–ª–æ–≤–∏—è –¥–ª—è Long
            'price_above_cloud': df['close'].iloc[-1] > df['senkou_span_a'].iloc[-1] and df['close'].iloc[-1] > df['senkou_span_b'].iloc[-1],
            'macd_above_signal': df['macd'].iloc[-1] > df['macd_signal'].iloc[-1],
            'rsi_oversold': df['rsi'].iloc[-1] < 40 and df['rsi'].iloc[-1] > df['rsi'].iloc[-2],
            'price_below_bb_lower': df['close'].iloc[-1] < df['bb_lower'].iloc[-1],
            'ema_crossover_long': df['ema_9'].iloc[-1] > df['ema_21'].iloc[-1] and df['ema_9'].iloc[-2] <= df['ema_21'].iloc[-2],
            'stoch_oversold': df['stoch_k'].iloc[-1] < 20 and df['stoch_d'].iloc[-1] < 20 and df['stoch_k'].iloc[-1] > df['stoch_k'].iloc[-2],
            'obv_uptrend': df['obv'].iloc[-1] > df['obv_ema'].iloc[-1],
            'parabolic_sar_long': df['close'].iloc[-1] > df['psar'].iloc[-1],
            
            # –£—Å–ª–æ–≤–∏—è –¥–ª—è Short
            'price_below_cloud': df['close'].iloc[-1] < df['senkou_span_a'].iloc[-1] and df['close'].iloc[-1] < df['senkou_span_b'].iloc[-1],
            'macd_below_signal': df['macd'].iloc[-1] < df['macd_signal'].iloc[-1],
            'rsi_overbought': df['rsi'].iloc[-1] > 70 and df['rsi'].iloc[-1] < df['rsi'].iloc[-2],
            'price_above_bb_upper': df['close'].iloc[-1] > df['bb_upper'].iloc[-1],
            'ema_crossover_short': df['ema_9'].iloc[-1] < df['ema_21'].iloc[-1] and df['ema_9'].iloc[-2] >= df['ema_21'].iloc[-2],
            'stoch_overbought': df['stoch_k'].iloc[-1] > 80 and df['stoch_d'].iloc[-1] > 80 and df['stoch_k'].iloc[-1] < df['stoch_k'].iloc[-2],
            'obv_downtrend': df['obv'].iloc[-1] < df['obv_ema'].iloc[-1],
            'parabolic_sar_short': df['close'].iloc[-1] < df['psar'].iloc[-1],
            
            # –û–±—â–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            'adx_strong_trend': df['adx'].iloc[-1] > 25,
            'volume_spike': df['volume'].iloc[-1] > df['volume'].rolling(window=20).mean().iloc[-1] * 1.5,
            'williams_r_bullish': df['wr'].iloc[-1] < -80 and df['wr'].iloc[-1] > df['wr'].iloc[-2],
            'williams_r_bearish': df['wr'].iloc[-1] > -20 and df['wr'].iloc[-1] < df['wr'].iloc[-2],
            
            # Supertrend –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            'supertrend_value': df['supertrend'].iloc[-1] if len(df) > atr_period else None,
            'supertrend_long': df['close'].iloc[-1] > df['supertrend'].iloc[-1] if len(df) > atr_period else False,
            'supertrend_short': df['close'].iloc[-1] < df['supertrend'].iloc[-1] if len(df) > atr_period else False
        }
        
        # Pattern Recognition Integration
        if config['use_pattern_recognition']:
            try:
                # Analyze patterns using the pattern recognition module
                pattern_results = analyze_patterns(df, config['pattern_lookback_period'])
                
                # Add pattern recognition info to indicators
                indicators['pattern_bullish_score'] = pattern_results['bullish_score']
                indicators['pattern_bearish_score'] = pattern_results['bearish_score']
                indicators['pattern_bullish'] = len(pattern_results['total_patterns']['bullish']) > 0
                indicators['pattern_bearish'] = len(pattern_results['total_patterns']['bearish']) > 0
                
                # Store detailed pattern information
                indicators['candlestick_patterns'] = pattern_results['candlestick_patterns']
                indicators['chart_patterns'] = pattern_results['chart_patterns']
                
                logger.debug(f"Pattern recognition: Bullish={indicators['pattern_bullish_score']}, Bearish={indicators['pattern_bearish_score']}")
            except Exception as e:
                logger.error(f"Error in pattern recognition: {e}")
        
        return indicators
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {e}")
        return None

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –¥–ª—è –ª–æ–Ω–≥–∞
def check_long_conditions(ind, df):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –¥–ª—è Long —Å–∏–≥–Ω–∞–ª–∞"""
    conditions = {
        'price_above_cloud': ind.get('price_above_cloud', False),
        'macd_above_signal': ind.get('macd_above_signal', False),
        'rsi_oversold': ind.get('rsi_oversold', False),
        'price_below_bb_lower': ind.get('price_below_bb_lower', False),
        'ema_crossover_long': ind.get('ema_crossover_long', False),
        'stoch_oversold': ind.get('stoch_oversold', False),
        'obv_uptrend': ind.get('obv_uptrend', False),
        'parabolic_sar_long': ind.get('parabolic_sar_long', False),
        'adx_strong_trend': ind.get('adx_strong_trend', False),
        'volume_spike': ind.get('volume_spike', False),
        'williams_r_bullish': ind.get('williams_r_bullish', False),
        'supertrend_long': ind.get('supertrend_long', False)
    }
    
    # BB+Supertrend –∫–æ–º–±–∏–Ω–∞—Ü–∏—è
    bb_width = ind.get('bb_width', 0)
    conditions['bbtrend_supertrend_long'] = (
        ind.get('price_below_bb_lower', False) and 
        ind.get('supertrend_long', False) and 
        bb_width > 0.1
    )
    
    # Add pattern recognition conditions if available
    if config.get('use_pattern_recognition', False):
        if 'pattern_bullish_score' in ind and 'pattern_bearish_score' in ind:
            # Pattern bullish score > bearish score is a bullish signal
            conditions['pattern_bullish'] = ind.get('pattern_bullish_score', 0) > ind.get('pattern_bearish_score', 0)
            
            # Add each individual candlestick pattern if present
            if 'candlestick_patterns' in ind and 'bullish' in ind['candlestick_patterns']:
                for pattern in ind['candlestick_patterns']['bullish']:
                    conditions[f'cdl_{pattern}'] = True
                    
            # Add each individual chart pattern if present
            if 'chart_patterns' in ind and 'bullish' in ind['chart_patterns']:
                for pattern in ind['chart_patterns']['bullish']:
                    conditions[f'chart_{pattern}'] = True
    
    return conditions

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –¥–ª—è —à–æ—Ä—Ç–∞
def check_short_conditions(ind, df):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –¥–ª—è Short —Å–∏–≥–Ω–∞–ª–∞"""
    conditions = {
        'price_below_cloud': ind.get('price_below_cloud', False),
        'macd_below_signal': ind.get('macd_below_signal', False),
        'rsi_overbought': ind.get('rsi_overbought', False),
        'price_above_bb_upper': ind.get('price_above_bb_upper', False),
        'ema_crossover_short': ind.get('ema_crossover_short', False),
        'stoch_overbought': ind.get('stoch_overbought', False),
        'obv_downtrend': ind.get('obv_downtrend', False),
        'parabolic_sar_short': ind.get('parabolic_sar_short', False),
        'adx_strong_trend': ind.get('adx_strong_trend', False),
        'volume_spike': ind.get('volume_spike', False),
        'williams_r_bearish': ind.get('williams_r_bearish', False),
        'supertrend_short': ind.get('supertrend_short', False)
    }
    
    # BB+Supertrend –∫–æ–º–±–∏–Ω–∞—Ü–∏—è
    bb_width = ind.get('bb_width', 0)
    conditions['bbtrend_supertrend_short'] = (
        ind.get('price_above_bb_upper', False) and 
        ind.get('supertrend_short', False) and 
        bb_width > 0.1
    )
    
    # Add pattern recognition conditions if available
    if config.get('use_pattern_recognition', False):
        if 'pattern_bullish_score' in ind and 'pattern_bearish_score' in ind:
            # Pattern bearish score > bullish score is a bearish signal
            conditions['pattern_bearish'] = ind.get('pattern_bearish_score', 0) > ind.get('pattern_bullish_score', 0)
            
            # Add each individual candlestick pattern if present
            if 'candlestick_patterns' in ind and 'bearish' in ind['candlestick_patterns']:
                for pattern in ind['candlestick_patterns']['bearish']:
                    conditions[f'cdl_{pattern}'] = True
                    
            # Add each individual chart pattern if present
            if 'chart_patterns' in ind and 'bearish' in ind['chart_patterns']:
                for pattern in ind['chart_patterns']['bearish']:
                    conditions[f'chart_{pattern}'] = True
    
    return conditions

# –ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
high_confidence_combinations = [
    ('rsi_oversold', 'macd_above_signal', 'adx_strong_trend'),
    ('price_above_cloud', 'ema_crossover_long', 'volume_spike'),
    ('rsi_oversold', 'price_below_bb_lower', 'stoch_oversold')
]

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞
def create_signal(symbol, signal_type, current_price, conditions, df, volume_usd, news):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–∏–≥–Ω–∞–ª–∞"""
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–Ω–µ—Ç–∞ –º–µ–º–Ω–æ–π
    base_symbol = symbol.split('/')[0].replace('USDT:USDT', '').replace('USDT', '')
    is_meme_coin = any(meme in base_symbol for meme in config['meme_coins'])
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –º–æ–Ω–µ—Ç—ã
    if is_meme_coin:
        leverage = config['meme_leverage']
        tp_percent = config['meme_tp_percent']
        offset_percent = config.get('meme_supertrend_offset_percent', 1.0)
        offset_atr = config.get('meme_supertrend_offset_atr', 1.0)
        sl_atr_multiplier = config.get('meme_sl_atr_multiplier', 2.0)
    else:
        leverage = config['leverage']
        tp_percent = config['tp_percent']
        offset_percent = config.get('supertrend_offset_percent', 0.5)
        offset_atr = config.get('supertrend_offset_atr', 0.5)
        sl_atr_multiplier = config.get('sl_atr_multiplier', 1.5)
    
    # –î–æ—Å—Ç—É–ø –∫ ATR –∏ –∑–Ω–∞—á–µ–Ω–∏—é —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥–∞
    atr_value = float(conditions.get('atr', 0))
    supertrend_value = conditions.get('supertrend_value')
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è entry_price
    entry_price = current_price
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥–∞
    if supertrend_value is None:
        logger.debug(f"{symbol}: –°—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥ –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ TP/SL")
        # –†–∞—Å—á–µ—Ç TP –∏ SL —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –º–µ—Ç–æ–¥–æ–º
        sl_percent = config['sl_percent']
        
        if signal_type == 'long':
            tp = round(entry_price * (1 + tp_percent / 100), 6)
            sl = round(entry_price * (1 - sl_percent / 100), 6)
        else:  # short
            tp = round(entry_price * (1 - tp_percent / 100), 6)
            sl = round(entry_price * (1 + sl_percent / 100), 6)
    else:
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç—Å—Ç—É–ø–∞ (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏–∑ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –∏ ATR)
        offset_by_percent = current_price * offset_percent / 100
        offset_by_atr = atr_value * offset_atr
        offset = max(offset_by_percent, offset_by_atr) if atr_value > 0 else offset_by_percent
        
        logger.debug(f"{symbol}: –û—Ç—Å—Ç—É–ø –¥–ª—è {signal_type}: {offset:.6f} ({offset_percent}% –∏–ª–∏ {offset_atr}*ATR)")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ TP –∏ SL –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥–∞
        if signal_type == 'long':
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Ü–µ–Ω–∞ —É—Å–ª–æ–≤–∏—è–º –≤—Ö–æ–¥–∞ —Å –æ—Ç—Å—Ç—É–ø–æ–º
            entry_with_offset = supertrend_value + offset
            if current_price < entry_with_offset:
                logger.debug(f"{symbol}: –¶–µ–Ω–∞ {current_price} –Ω–∏–∂–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ —Å –æ—Ç—Å—Ç—É–ø–æ–º {entry_with_offset}")
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É –∫–∞–∫ —Ç–æ—á–∫—É –≤—Ö–æ–¥–∞ (–±–µ–∑ –æ—Ç—Å—Ç—É–ø–∞)
                entry_price = current_price
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–∫—É –≤—Ö–æ–¥–∞ —Å –æ—Ç—Å—Ç—É–ø–æ–º
                entry_price = entry_with_offset
                logger.debug(f"{symbol}: –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ —Å –æ—Ç—Å—Ç—É–ø–æ–º: {entry_price}")
            
            # TP —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤—ã—à–µ —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥–∞
            tp = round(supertrend_value * 1.05, 6)
            
            # SL –Ω–∞ –æ—Å–Ω–æ–≤–µ ATR (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω) –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–π SL
            if atr_value > 0:
                sl = round(entry_price - (atr_value * sl_atr_multiplier), 6)
            else:
                sl_percent = config['sl_percent']
                sl = round(entry_price * (1 - sl_percent / 100), 6)
        else:  # short
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Ü–µ–Ω–∞ —É—Å–ª–æ–≤–∏—è–º –≤—Ö–æ–¥–∞ —Å –æ—Ç—Å—Ç—É–ø–æ–º
            entry_with_offset = supertrend_value - offset
            if current_price > entry_with_offset:
                logger.debug(f"{symbol}: –¶–µ–Ω–∞ {current_price} –≤—ã—à–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ —Å –æ—Ç—Å—Ç—É–ø–æ–º {entry_with_offset}")
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Ü–µ–Ω—É –∫–∞–∫ —Ç–æ—á–∫—É –≤—Ö–æ–¥–∞ (–±–µ–∑ –æ—Ç—Å—Ç—É–ø–∞)
                entry_price = current_price
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–∫—É –≤—Ö–æ–¥–∞ —Å –æ—Ç—Å—Ç—É–ø–æ–º
                entry_price = entry_with_offset
                logger.debug(f"{symbol}: –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ —Å –æ—Ç—Å—Ç—É–ø–æ–º: {entry_price}")
            
            # TP —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∏–∂–µ —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥–∞
            tp = round(supertrend_value * 0.95, 6)
            
            # SL –Ω–∞ –æ—Å–Ω–æ–≤–µ ATR (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω) –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–π SL
            if atr_value > 0:
                sl = round(entry_price + (atr_value * sl_atr_multiplier), 6)
            else:
                sl_percent = config['sl_percent']
                sl = round(entry_price * (1 + sl_percent / 100), 6)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ High Confidence –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
    high_confidence_combo = []
    
    # –°—á–∏—Ç–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ä–∞–±–æ—Ç–∞–≤—à–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
    active_indicators = [key for key, value in conditions.items() if value and not key.startswith('cdl_') and not key.startswith('chart_')]
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    for combo in high_confidence_combinations:
        if all(ind in active_indicators for ind in combo):
            high_confidence_combo = combo
            break
    
    # –†–∞—Å—á—ë—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –ø—Ä–∏–±—ã–ª–∏/—É–±—ã—Ç–∫–∞
    tp_percent_calc = abs((tp - entry_price) / entry_price * 100)
    sl_percent_calc = abs((sl - entry_price) / entry_price * 100)
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞
    logger.debug(f"–°–∏–≥–Ω–∞–ª: {signal_type}, –í—Ö–æ–¥: {entry_price}, TP: {tp}, SL: {sl}")
    logger.debug(f"–ê–∫—Ç–∏–≤–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ({len(active_indicators)}): {active_indicators}")
    if high_confidence_combo:
        logger.debug(f"–ö–æ–º–±–∏–Ω–∞—Ü–∏—è –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {high_confidence_combo}")
    
    return {
        'symbol': symbol,
        'type': signal_type,
        'entry_price': entry_price,
        'tp': tp,
        'sl': sl,
        'tp_percent': tp_percent_calc,
        'sl_percent': sl_percent_calc,
        'indicators': conditions,
        'volume_usd': volume_usd,
        'timestamp': datetime.utcnow().isoformat() + 'Z',
        'high_confidence_combo': high_confidence_combo,
        'news': news,
        'leverage': leverage,
        'position_size': config['position_size_usd'],
        'active_indicators': active_indicators,
        'active_indicators_count': len(active_indicators),
        'supertrend_value': supertrend_value
    }

# –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ —Å–∏–≥–Ω–∞–ª–µ
async def send_signal_notification(signal):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ–ø–æ–≤–µ—â–µ–Ω–∏—è –æ –Ω–æ–≤–æ–º —Å–∏–≥–Ω–∞–ª–µ –≤ Telegram"""
    try:
        symbol = signal['symbol'].replace('USDT:USDT', 'USDT')
        
        # –≠–º–æ–¥–∑–∏ –∏ —Å—Ç–∏–ª—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å–∏–≥–Ω–∞–ª–∞
        if signal['type'] == 'long':
            emoji = "üìà"
            signal_type = "LONG üü¢"
        else:
            emoji = "üìâ"
            signal_type = "SHORT üî¥"
        
        # –†–∞—Å—á—ë—Ç TP –∏ SL –¥–ª—è –º–µ–º–Ω—ã—Ö –º–æ–Ω–µ—Ç
        base_symbol = symbol.split('/')[0].replace('USDT', '')
        
        if any(meme in base_symbol for meme in config['meme_coins']):
            tp_percent = config['meme_tp_percent']
            leverage = config['meme_leverage']
            meme_tag = " üö®MEMEüö®"
        else:
            tp_percent = config['tp_percent']
            leverage = config['leverage']
            meme_tag = ""
        
        entry_price = signal['entry_price']
        tp_price = signal['tp']
        sl_price = signal['sl']
        
        # –†–∞—Å—á—ë—Ç P/L
        tp_pl_percent = signal.get('tp_percent', tp_percent)
        sl_pl_percent = signal.get('sl_percent', config['sl_percent'])
        tp_pl_usd = round(config['position_size_usd'] * leverage * tp_pl_percent / 100, 2)
        sl_pl_usd = round(config['position_size_usd'] * leverage * sl_pl_percent / 100, 2)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        message = f"{emoji} {signal_type} {symbol}{meme_tag}\n\n"
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Ö–æ–¥–µ –∏ –°—É–ø–µ—Ä—Ç—Ä–µ–Ω–¥–µ
        if 'supertrend_value' in signal and signal['supertrend_value'] is not None:
            supertrend_value = signal['supertrend_value']
            message += f"üí∞ –í—Ö–æ–¥: {entry_price}"
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ—Ç—Å—Ç—É–ø–µ –æ—Ç –°—É–ø–µ—Ä—Ç—Ä–µ–Ω–¥–∞
            if signal['type'] == 'long':
                if entry_price > supertrend_value:
                    offset = round((entry_price - supertrend_value) / supertrend_value * 100, 2)
                    message += f" (SuperTrend + {offset}%)\n"
                else:
                    # –ï—Å–ª–∏ —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω–æ–π (–Ω–∏–∂–µ —Ä–∞—Å—á–µ—Ç–Ω–æ–π —Å –æ—Ç—Å—Ç—É–ø–æ–º)
                    message += " (–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞)\n"
            else:  # short
                if entry_price < supertrend_value:
                    offset = round((supertrend_value - entry_price) / supertrend_value * 100, 2)
                    message += f" (SuperTrend - {offset}%)\n"
                else:
                    # –ï—Å–ª–∏ —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω–æ–π (–≤—ã—à–µ —Ä–∞—Å—á–µ—Ç–Ω–æ–π —Å –æ—Ç—Å—Ç—É–ø–æ–º)
                    message += " (–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞)\n"
                
            message += f"üéØ TP: {tp_price} (+{tp_pl_percent:.2f}% / +${tp_pl_usd})\n"
            message += f"üõë SL: {sl_price} (-{sl_pl_percent:.2f}% / -${sl_pl_usd})\n"
            message += f"üìä SuperTrend: {supertrend_value}\n"
        else:
            message += f"üí∞ –í—Ö–æ–¥: {entry_price}\n"
            message += f"üéØ TP: {tp_price} (+{tp_pl_percent:.2f}% / +${tp_pl_usd})\n"
            message += f"üõë SL: {sl_price} (-{sl_pl_percent:.2f}% / -${sl_pl_usd})\n"
            
        message += f"‚öôÔ∏è –õ–µ–≤–µ—Ä–∏–¥–∂: {leverage}x\n"
        
        # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–º–∞ (–≤ –º–∏–ª–ª–∏–æ–Ω–∞—Ö –¥–æ–ª–ª–∞—Ä–æ–≤)
        if 'volume_usd' in signal and signal['volume_usd'] > 0:
            volume_in_millions = round(signal['volume_usd']/1000000, 2)
            message += f"üíµ –û–±—ä—ë–º –∑–∞ 24—á: ${volume_in_millions}M\n"
        else:
            message += "üíµ –û–±—ä—ë–º –∑–∞ 24—á: N/A\n"
        
        # Fear & Greed Index –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if 'fng_value' in signal:
            fng_value = signal['fng_value']
            fng_status = "–°—Ç—Ä–∞—Ö" if fng_value < 30 else "–ñ–∞–¥–Ω–æ—Å—Ç—å" if fng_value > 70 else "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ"
            message += f"üò± Fear & Greed: {fng_value} ({fng_status})\n"
            
            if 'fng_bonus' in signal:
                message += f"‚ö° F&G –±–æ–Ω—É—Å: +{signal['fng_bonus']}\n"
        
        message += "\n"
        
        # ML prediction info if available
        if 'ml_prediction' in signal and signal['ml_prediction']:
            ml_conf = signal['ml_prediction']['confidence'] * 100
            direction_emoji = "üìà" if signal['ml_prediction']['direction'] == 'up' else "üìâ"
            message += f"ü§ñ ML: {direction_emoji} {ml_conf:.1f}% —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"
            
            if 'ml_bonus' in signal:
                message += f" (+{signal['ml_bonus']} –∫ —Å—á—ë—Ç—É)"
                
            message += "\n\n"
        
        # –ö–ª—é—á–µ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        key_indicators = [
            'price_above_cloud' if signal['type'] == 'long' else 'price_below_cloud',
            'macd_above_signal' if signal['type'] == 'long' else 'macd_below_signal',
            'rsi_oversold' if signal['type'] == 'long' else 'rsi_overbought',
            'price_below_bb_lower' if signal['type'] == 'long' else 'price_above_bb_upper',
            'ema_crossover_long' if signal['type'] == 'long' else 'ema_crossover_short',
            'stoch_oversold' if signal['type'] == 'long' else 'stoch_overbought',
            'obv_uptrend' if signal['type'] == 'long' else 'obv_downtrend',
            'parabolic_sar_long' if signal['type'] == 'long' else 'parabolic_sar_short',
            'adx_strong_trend',
            'volume_spike',
            'supertrend_long' if signal['type'] == 'long' else 'supertrend_short',
            'bbtrend_supertrend_long' if signal['type'] == 'long' else 'bbtrend_supertrend_short'
        ]
        indicator_names = {
            'price_above_cloud': 'Ichimoku Cloud',
            'price_below_cloud': 'Ichimoku Cloud',
            'macd_above_signal': 'MACD Above Signal',
            'macd_below_signal': 'MACD Below Signal',
            'rsi_oversold': 'RSI Oversold',
            'rsi_overbought': 'RSI Overbought',
            'price_below_bb_lower': 'Bollinger Bands Lower',
            'price_above_bb_upper': 'Bollinger Bands Upper',
            'ema_crossover_long': 'EMA Crossover',
            'ema_crossover_short': 'EMA Crossover',
            'stoch_oversold': 'Stochastic Oversold',
            'stoch_overbought': 'Stochastic Overbought',
            'obv_uptrend': 'OBV Uptrend',
            'obv_downtrend': 'OBV Downtrend',
            'parabolic_sar_long': 'Parabolic SAR',
            'parabolic_sar_short': 'Parabolic SAR',
            'adx_strong_trend': 'ADX Strong Trend',
            'volume_spike': 'Volume Spike',
            'supertrend_long': 'SuperTrend Long',
            'supertrend_short': 'SuperTrend Short',
            'bbtrend_supertrend_long': 'BB+SuperTrend Long',
            'bbtrend_supertrend_short': 'BB+SuperTrend Short'
        }
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (–∏—Å–∫–ª—é—á–∞—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã cdl_ –∏ chart_)
        active_count = sum(
            1 for key, value in signal['indicators'].items() 
            if value and not key.startswith('cdl_') and not key.startswith('chart_')
        )
        
        total_indicators = len([
            key for key in signal['indicators'].keys() 
            if not key.startswith('cdl_') and not key.startswith('chart_')
        ])
        
        message += f"üîç –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã [{active_count}/{total_indicators}]:\n"
        for ind in key_indicators:
            status = "‚úîÔ∏è" if signal['indicators'].get(ind) else "‚úò"
            message += f"  [{status}] {indicator_names.get(ind, ind)}\n"
        
        # –í—ã–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ BBTrend+SuperTrend
        if signal['indicators'].get('bbtrend_supertrend_long' if signal['type'] == 'long' else 'bbtrend_supertrend_short', False):
            message += f"\n‚ú® –°—Ç—Ä–∞—Ç–µ–≥–∏—è BB+SuperTrend –∞–∫—Ç–∏–≤–Ω–∞!\n"
        
        if signal['high_confidence_combo']:
            message += f"üî• High Confidence: {', '.join(indicator_names.get(ind, ind) for ind in signal['high_confidence_combo'])}\n"
        
        message += f"üì∞ –ù–æ–≤–æ—Å—Ç–∏: {signal['news']}\n"
        message += f"‚ö†Ô∏è –ù–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è!"
        
        await send_telegram_message(message)
        logger.info(f"–°–∏–≥–Ω–∞–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {signal['type']} –Ω–∞ {signal['symbol']}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–∏–≥–Ω–∞–ª–∞: {e}")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
last_signals = {}

# –ê–Ω–∞–ª–∏–∑ —Å–∏–≥–Ω–∞–ª–æ–≤
async def analyze_signals(symbol, indicators, df, volume_usd, price_change_1h):
    try:
        if indicators is None:
            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω {symbol}: –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã")
            return None
        
        long_conditions = check_long_conditions(indicators, df)
        short_conditions = check_short_conditions(indicators, df)
        
        # Count normal indicators
        long_score = sum(
            value for key, value in long_conditions.items() 
            if not (key.startswith('cdl_') or key.startswith('chart_') or key == 'pattern_bullish')
        )
        short_score = sum(
            value for key, value in short_conditions.items() 
            if not (key.startswith('cdl_') or key.startswith('chart_') or key == 'pattern_bearish')
        )
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        active_long_indicators = [key for key, value in long_conditions.items() if value and not (key.startswith('cdl_') or key.startswith('chart_'))]
        active_short_indicators = [key for key, value in short_conditions.items() if value and not (key.startswith('cdl_') or key.startswith('chart_'))]
        
        logger.debug(f"–ê–∫—Ç–∏–≤–Ω—ã–µ long –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è {symbol}: {active_long_indicators}")
        logger.debug(f"–ê–∫—Ç–∏–≤–Ω—ã–µ short –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è {symbol}: {active_short_indicators}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ BBTrend+SuperTrend
        bbtrend_supertrend_long = long_conditions.get('bbtrend_supertrend_long', False)
        bbtrend_supertrend_short = short_conditions.get('bbtrend_supertrend_short', False)
        
        if bbtrend_supertrend_long:
            logger.debug(f"{symbol}: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è BB+SuperTrend Long")
        elif bbtrend_supertrend_short:
            logger.debug(f"{symbol}: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è BB+SuperTrend Short")
        
        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Fear & Greed Index
        fng_value = indicators.get('fng_value', 50)  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 50 (–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ)
        fng_bonus = 0
        
        # –ï—Å–ª–∏ FNG < 30 (—Å—Ç—Ä–∞—Ö) –∏ –µ—Å—Ç—å —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥ –ª–æ–Ω–≥ - —ç—Ç–æ —Ö–æ—Ä–æ—à–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞
        if fng_value < 30 and long_conditions.get('supertrend_long', False):
            fng_bonus = 1.5
            long_score += fng_bonus
            logger.debug(f"{symbol}: Fear & Greed: {fng_value} (—Å—Ç—Ä–∞—Ö) - –±–æ–Ω—É—Å –∫ long —Å–∏–≥–Ω–∞–ª—É: +{fng_bonus}")
            
        # –ï—Å–ª–∏ FNG > 70 (–∂–∞–¥–Ω–æ—Å—Ç—å) –∏ –µ—Å—Ç—å —Å—É–ø–µ—Ä—Ç—Ç—Ä–µ–Ω–¥ —à–æ—Ä—Ç - —ç—Ç–æ —Ö–æ—Ä–æ—à–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞
        elif fng_value > 70 and short_conditions.get('supertrend_short', False):
            fng_bonus = 1.5
            short_score += fng_bonus
            logger.debug(f"{symbol}: Fear & Greed: {fng_value} (–∂–∞–¥–Ω–æ—Å—Ç—å) - –±–æ–Ω—É—Å –∫ short —Å–∏–≥–Ω–∞–ª—É: +{fng_bonus}")
        
        # Add weighted pattern scores if enabled
        pattern_score_long = 0
        pattern_score_short = 0
        
        if config.get('use_pattern_recognition', False):
            # Count candlestick patterns
            cdl_patterns_long = sum(
                1 for key, value in long_conditions.items() 
                if key.startswith('cdl_') and value
            )
            cdl_patterns_short = sum(
                1 for key, value in short_conditions.items() 
                if key.startswith('cdl_') and value
            )
            
            # Count chart patterns
            chart_patterns_long = sum(
                1 for key, value in long_conditions.items() 
                if key.startswith('chart_') and value
            )
            chart_patterns_short = sum(
                1 for key, value in short_conditions.items() 
                if key.startswith('chart_') and value
            )
            
            # Add general pattern match if present
            if long_conditions.get('pattern_bullish', False):
                cdl_patterns_long += 1
            
            if short_conditions.get('pattern_bearish', False):
                cdl_patterns_short += 1
            
            # Add weighted pattern scores
            pattern_weight = config.get('pattern_weight', 2.0)
            pattern_score_long = (cdl_patterns_long + chart_patterns_long) * pattern_weight
            pattern_score_short = (cdl_patterns_short + chart_patterns_short) * pattern_weight
            
            long_score += pattern_score_long
            short_score += pattern_score_short
            
            logger.debug(f"{symbol}: Added pattern weights - Long: +{pattern_score_long}, Short: +{pattern_score_short}")
        
        # Get total count of indicators (excluding patterns which are already weighted)
        total_indicators = len([
            key for key in set(list(long_conditions.keys()) + list(short_conditions.keys()))
            if not (key.startswith('cdl_') or key.startswith('chart_') or key in ['pattern_bullish', 'pattern_bearish'])
        ])
        
        logger.debug(f"{symbol}: Long Score = {long_score}/{total_indicators} (–ë–∞–∑–æ–≤—ã–µ: {long_score - pattern_score_long - fng_bonus if fng_bonus > 0 and long_score > short_score else long_score - pattern_score_long})")
        logger.debug(f"{symbol}: Short Score = {short_score}/{total_indicators} (–ë–∞–∑–æ–≤—ã–µ: {short_score - pattern_score_short - fng_bonus if fng_bonus > 0 and short_score > long_score else short_score - pattern_score_short})")
        
        # Get news sentiment
        news = await check_news(symbol, price_change_1h)
        
        # Get ML model prediction if available
        ml_prediction = None
        ml_bonus_long = 0
        ml_bonus_short = 0
        
        if config.get('use_ml_predictions', False):
            ml_prediction = await get_ml_prediction(symbol, ohlcv_to_dataframe(df))
            
            if ml_prediction:
                ml_direction = ml_prediction['direction']
                ml_confidence = ml_prediction['confidence']
                logger.debug(f"ML-–ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è {symbol}: {ml_direction.upper()} —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {ml_confidence:.2f}")
                
                # Add ML prediction weight to appropriate score
                if ml_direction == 'up' and ml_confidence >= config.get('ml_confidence_threshold', 0.65):
                    # ML predicts price will go up, add to long score
                    ml_bonus_long = 2
                    long_score += ml_bonus_long
                    logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ ML-–≤–µ—Å–∞ –∫ long —Å–∏–≥–Ω–∞–ª—É –¥–ª—è {symbol} (+{ml_bonus_long})")
                elif ml_direction == 'down' and ml_confidence >= config.get('ml_confidence_threshold', 0.65):
                    # ML predicts price will go down, add to short score
                    ml_bonus_short = 2
                    short_score += ml_bonus_short
                    logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ ML-–≤–µ—Å–∞ –∫ short —Å–∏–≥–Ω–∞–ª—É –¥–ª—è {symbol} (+{ml_bonus_short})")
        
        # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –≤ 8 –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤, 5 –¥–ª—è BB+SuperTrend
        fixed_threshold = 8
        bbtrend_supertrend_threshold = 5
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏–≥–Ω–∞–ª, –µ—Å–ª–∏ —á–∏—Å–ª–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
        signal = None
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ BB + Supertrend
        if bbtrend_supertrend_long and long_score >= bbtrend_supertrend_threshold:
            logger.debug(f"{symbol}: –°–∏–≥–Ω–∞–ª Long –Ω–∞ –æ—Å–Ω–æ–≤–µ BB+SuperTrend (—Å–∫–æ—Ä: {long_score}, –æ—Å–Ω–æ–≤–Ω—ã–µ: {len(active_long_indicators)})")
            signal = create_signal(symbol, 'long', indicators['current_price'], long_conditions, df, volume_usd, news)
            if ml_prediction and ml_prediction['direction'] == 'up':
                signal['ml_prediction'] = {'direction': 'up', 'confidence': ml_prediction['confidence']}
                signal['ml_bonus'] = ml_bonus_long
            
            # Add pattern information to signal if available
            if config['use_pattern_recognition'] and 'candlestick_patterns' in indicators and 'chart_patterns' in indicators:
                signal['patterns'] = {
                    'candlestick': indicators['candlestick_patterns']['bullish'],
                    'chart': indicators['chart_patterns']['bullish']
                }
        elif bbtrend_supertrend_short and short_score >= bbtrend_supertrend_threshold:
            logger.debug(f"{symbol}: –°–∏–≥–Ω–∞–ª Short –Ω–∞ –æ—Å–Ω–æ–≤–µ BB+SuperTrend (—Å–∫–æ—Ä: {short_score}, –æ—Å–Ω–æ–≤–Ω—ã–µ: {len(active_short_indicators)})")
            signal = create_signal(symbol, 'short', indicators['current_price'], short_conditions, df, volume_usd, news)
            if ml_prediction and ml_prediction['direction'] == 'down':
                signal['ml_prediction'] = {'direction': 'down', 'confidence': ml_prediction['confidence']}
                signal['ml_bonus'] = ml_bonus_short
            
            # Add pattern information to signal if available
            if config['use_pattern_recognition'] and 'candlestick_patterns' in indicators and 'chart_patterns' in indicators:
                signal['patterns'] = {
                    'candlestick': indicators['candlestick_patterns']['bearish'],
                    'chart': indicators['chart_patterns']['bearish']
                }
        # –û–±—ã—á–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã, –µ—Å–ª–∏ BBTrend –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
        elif long_score >= fixed_threshold:
            logger.debug(f"{symbol}: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π Long —Å–∏–≥–Ω–∞–ª (—Å–∫–æ—Ä: {long_score}, –æ—Å–Ω–æ–≤–Ω—ã–µ: {len(active_long_indicators)})")
            signal = create_signal(symbol, 'long', indicators['current_price'], long_conditions, df, volume_usd, news)
            if ml_prediction and ml_prediction['direction'] == 'up':
                signal['ml_prediction'] = {'direction': 'up', 'confidence': ml_prediction['confidence']}
                signal['ml_bonus'] = ml_bonus_long
            
            # Add pattern information to signal if available
            if config['use_pattern_recognition'] and 'candlestick_patterns' in indicators and 'chart_patterns' in indicators:
                signal['patterns'] = {
                    'candlestick': indicators['candlestick_patterns']['bullish'],
                    'chart': indicators['chart_patterns']['bullish']
                }
        elif short_score >= fixed_threshold:
            logger.debug(f"{symbol}: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π Short —Å–∏–≥–Ω–∞–ª (—Å–∫–æ—Ä: {short_score}, –æ—Å–Ω–æ–≤–Ω—ã–µ: {len(active_short_indicators)})")
            signal = create_signal(symbol, 'short', indicators['current_price'], short_conditions, df, volume_usd, news)
            if ml_prediction and ml_prediction['direction'] == 'down':
                signal['ml_prediction'] = {'direction': 'down', 'confidence': ml_prediction['confidence']}
                signal['ml_bonus'] = ml_bonus_short
            
            # Add pattern information to signal if available
            if config['use_pattern_recognition'] and 'candlestick_patterns' in indicators and 'chart_patterns' in indicators:
                signal['patterns'] = {
                    'candlestick': indicators['candlestick_patterns']['bearish'],
                    'chart': indicators['chart_patterns']['bearish']
                }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        if signal:
            global last_signals
            last_signal = last_signals.get(symbol)
            
            if last_signal:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–∏–ø–∞ —Å–∏–≥–Ω–∞–ª–∞
                if last_signal['type'] == signal['type']:
                    # –ï—Å–ª–∏ —Ç–∏–ø —Å–∏–≥–Ω–∞–ª–∞ —Ç–æ—Ç –∂–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –≤—Ö–æ–¥–∞
                    price_diff = abs(signal['entry_price'] - last_signal['entry_price']) / last_signal['entry_price'] * 100
                    if price_diff < 1.0:
                        logger.debug(f"–ü—Ä–æ–ø—É—Å–∫ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è {symbol}: —Ç–∏–ø {signal['type']}, –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –≤—Å–µ–≥–æ {price_diff:.2f}%")
                        return None
                    else:
                        logger.debug(f"–ù–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –¥–ª—è {symbol} —Å —Ç–µ–º –∂–µ —Ç–∏–ø–æ–º, –Ω–æ —Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º —Ü–µ–Ω—ã {price_diff:.2f}%")
                else:
                    logger.debug(f"–ù–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª –¥–ª—è {symbol} —Å –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–º —Ç–∏–ø–æ–º: {last_signal['type']} -> {signal['type']}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ F&G –±–æ–Ω—É—Å–µ –≤ —Å–∏–≥–Ω–∞–ª
            if fng_bonus > 0:
                signal['fng_bonus'] = fng_bonus
                signal['fng_value'] = fng_value
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏–≥–Ω–∞–ª –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–ª—è —ç—Ç–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
            last_signals[symbol] = signal
            
            return signal
        
        return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è {symbol}: {e}")
        return None

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä—ã
async def process_pair(symbol, timeframe=config['timeframe'], limit=config['ohlcv_limit'], volume_data=None):
    logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {symbol}")
    try:
        ohlcv = await load_ohlcv(symbol, timeframe, limit)
        if not ohlcv or len(ohlcv) < limit:
            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω {symbol}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö OHLCV (–ø–æ–ª—É—á–µ–Ω–æ {len(ohlcv) if ohlcv else 0} —Å—Ç—Ä–æ–∫)")
            return None

        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        if df[['open', 'high', 'low', 'close', 'volume']].isna().any().any() or len(df) < 14:
            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω {symbol}: NaN –≤ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ç—Ä–æ–∫ ({len(df)})")
            return None

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º–ø–∞
        current_price = df['close'].iloc[-1]
        price_change_1h = abs((current_price - df['close'].iloc[-2]) / df['close'].iloc[-2] * 100) if len(df) > 1 and df['close'].iloc[-2] != 0 else 0
        if price_change_1h > config['pump_price_threshold']:
            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω {symbol}: –ø–∞–º–ø (—Ä–æ—Å—Ç {price_change_1h:.2f}%)")
            return None

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä—ë–º–∞
        avg_volume = df['volume'].rolling(window=20).mean().iloc[-1]
        if not pd.isna(avg_volume) and df['volume'].iloc[-1] != 0:
            volume_spike = df['volume'].iloc[-1] > avg_volume * config['pump_volume_multiplier']
            if volume_spike:
                logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω {symbol}: Volume Spike (x{config['pump_volume_multiplier']})")
                return None

        # –ü–æ–ª—É—á–µ–Ω–∏–µ Fear & Greed
        fng_value = await fetch_fear_and_greed()
        
        # –†–∞—Å—á—ë—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        indicators = calculate_indicators(df, fng_value)
        if indicators is None:
            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω {symbol}: –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã")
            return None
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        if pd.isna(indicators['atr']) or pd.isna(indicators['avg_atr']) or indicators['atr'] < indicators['avg_atr'] * config['atr_volatility_multiplier']:
            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω {symbol}: –Ω–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏–ª–∏ NaN –≤ ATR")
            return None
            
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ ML-–º–æ–¥–µ–ª–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤ —Ñ–æ–Ω–µ, –µ—Å–ª–∏ –µ—â—ë –Ω–µ –æ–±—É—á–µ–Ω–∞
        if config['use_ml_predictions']:
            model_dir = 'models'
            model_path = os.path.join(model_dir, f'{symbol.replace("/", "_")}_{timeframe}_model.pkl')
            if not os.path.exists(model_path):
                asyncio.create_task(train_ml_model(symbol, timeframe))
                logger.debug(f"–ó–∞–ø—É—â–µ–Ω–æ —Ñ–æ–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ ML-–º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}")

        # –ê–Ω–∞–ª–∏–∑ —Å–∏–≥–Ω–∞–ª–æ–≤
        volume_usd = volume_data.get(symbol, 0)
        signal = await analyze_signals(symbol, indicators, df, volume_usd, price_change_1h)
        if signal:
            await send_signal_notification(signal)
            log_signal_to_csv(signal)
        
        return signal
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {symbol}: {e}")
        return None

# –ë—ç–∫—Ç–µ—Å—Ç —Å–∏–º–≤–æ–ª–∞
async def backtest_symbol(symbol, timeframe='1h', start_date=None, end_date=None, send_notifications=False):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö."""
    logger.info(f"–ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∞ –¥–ª—è {symbol}")
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞—Ç –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
        since = int(pd.Timestamp(start_date).timestamp() * 1000) if start_date else None
        ohlcv = await bybit.fetch_ohlcv(symbol, timeframe, since=since, limit=1000)
        if not ohlcv or len(ohlcv) < 20:
            logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {len(ohlcv) if ohlcv else 0} —Å—Ç—Ä–æ–∫")
            return None

        df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        
        signals = []
        fng_value = await fetch_fear_and_greed()
        
        # –°–∏–º—É–ª—è—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ä–∞
        for i in range(20, len(df)):
            window_df = df.iloc[:i].copy()
            indicators = calculate_indicators(window_df, fng_value)
            if indicators is None:
                continue
            
            price_change_1h = abs((window_df['close'].iloc[-1] - window_df['close'].iloc[-2]) / window_df['close'].iloc[-2] * 100) if len(window_df) > 1 else 0
            volume_usd = window_df['volume'].iloc[-1] * window_df['close'].iloc[-1]
            
            signal = await analyze_signals(symbol, indicators, window_df, volume_usd, price_change_1h)
            if signal:
                signals.append(signal)
                logger.debug(f"–ë—ç–∫—Ç–µ—Å—Ç: –ù–∞–π–¥–µ–Ω —Å–∏–≥–Ω–∞–ª –¥–ª—è {symbol} –Ω–∞ {window_df['timestamp'].iloc[-1]}")
                if send_notifications:
                    await send_signal_notification(signal)
                log_signal_to_csv(signal)
        
        logger.info(f"–ë—ç–∫—Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à—ë–Ω: {len(signals)} —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è {symbol}")
        return signals
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –±—ç–∫—Ç–µ—Å—Ç–∞ –¥–ª—è {symbol}: {e}")
        return None

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è ML-–º–æ–¥–µ–ª–µ–π
async def train_ml_model(symbol, timeframe=config['timeframe'], force_retrain=False):
    """–û–±—É—á–µ–Ω–∏–µ ML-–º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞"""
    try:
        model_dir = 'models'
        os.makedirs(model_dir, exist_ok=True)
        
        model = CryptoMLPredictor(symbol, timeframe, model_dir)
        model_exists = model.load_model()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å
        if model_exists and not force_retrain:
            model_path = model.model_path
            if os.path.exists(model_path):
                mtime = datetime.fromtimestamp(os.path.getmtime(model_path))
                days_since_train = (datetime.now() - mtime).days
                if days_since_train < config['ml_retrain_days']:
                    logger.debug(f"–ú–æ–¥–µ–ª—å –¥–ª—è {symbol} —É–∂–µ –æ–±—É—á–µ–Ω–∞ –∏ –∞–∫—Ç—É–∞–ª—å–Ω–∞ ({days_since_train} –¥–Ω–µ–π –Ω–∞–∑–∞–¥)")
                    return True
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (–±–æ–ª—å—à–µ —Å–≤–µ—á–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)
        ohlcv = await load_ohlcv(symbol, timeframe, limit=240)  # –ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        if not ohlcv or len(ohlcv) < 100:
            logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–∏ {symbol}: {len(ohlcv) if ohlcv else 0} —Å–≤–µ—á–µ–π")
            return False
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame
        df = ohlcv_to_dataframe(ohlcv)
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        result = model.train(df)
        accuracy = result['test_accuracy']
        logger.info(f"ML-–º–æ–¥–µ–ª—å –¥–ª—è {symbol} –æ–±—É—á–µ–Ω–∞ —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {accuracy:.2f}")
        
        return accuracy >= config['min_ml_accuracy']
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}: {e}")
        return False

async def get_ml_prediction(symbol, df=None, timeframe=config['timeframe']):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –æ—Ç ML-–º–æ–¥–µ–ª–∏"""
    try:
        if not config['use_ml_predictions']:
            return None
            
        model = CryptoMLPredictor(symbol, timeframe, 'models')
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not model.load_model():
            # –û–±—É—á–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –Ω–µ—Ç
            success = await train_ml_model(symbol, timeframe)
            if not success:
                return None
        
        # –ï—Å–ª–∏ DataFrame –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω, –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        if df is None:
            ohlcv = await load_ohlcv(symbol, timeframe)
            if not ohlcv:
                return None
            df = ohlcv_to_dataframe(ohlcv)
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑
        prediction = model.predict(df)
        
        if not prediction:
            return None
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞
        if prediction['confidence'] < config['ml_confidence_threshold']:
            logger.debug(f"ML-–ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è {symbol} –∏–º–µ–µ—Ç —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {prediction['confidence']:.2f}")
            return None
            
        logger.info(f"ML-–ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è {symbol}: {prediction['direction'].upper()} —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {prediction['confidence']:.2f}")
        
        return prediction
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è ML-–ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è {symbol}: {e}")
        return None

async def batch_train_ml_models(symbols, timeframe=config['timeframe']):
    """–ü–∞–∫–µ—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ML-–º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–ø–∏—Å–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤"""
    if not config['use_ml_predictions']:
        return
    
    logger.info(f"–ù–∞—á–∞–ª–æ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–µ–π –¥–ª—è {len(symbols)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–µ–π, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    os.makedirs('models', exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤
    symbol_data = {}
    for symbol in symbols:
        try:
            ohlcv = await load_ohlcv(symbol, timeframe, limit=240)  # –ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            if ohlcv and len(ohlcv) >= 100:
                df = ohlcv_to_dataframe(ohlcv)
                symbol_data[symbol] = df
            else:
                logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–∏ {symbol}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML-–º–æ–¥–µ–ª–∏ {symbol}: {e}")
    
    if not symbol_data:
        logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML-–º–æ–¥–µ–ª–µ–π")
        return
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –ø–∞–∫–µ—Ç–Ω–æ
    results = await batch_train_models(symbol_data, timeframe, 'models')
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    successful = sum(1 for result in results.values() if result.get('success', False))
    logger.info(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ –æ–±—É—á–µ–Ω–∏–µ ML-–º–æ–¥–µ–ª–µ–π: {successful}/{len(results)} —É—Å–ø–µ—à–Ω–æ")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∏–º–≤–æ–ª—ã —Å —Ö–æ—Ä–æ—à–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏
    good_models = [
        symbol for symbol, result in results.items()
        if result.get('success', False) and result.get('accuracy', 0) >= config['min_ml_accuracy']
    ]
    
    return good_models

# –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
async def main():
    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Telegram –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
        await test_telegram()
        
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ –∫—ç—à–∞
        clean_old_cache()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä—ã–Ω–∫–æ–≤
        symbols = await load_markets()
        if not symbols:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä—ã–Ω–∫–∏")
            return
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        parser = argparse.ArgumentParser(description='Crypto Signals Bot')
        parser.add_argument('--backtest', help='Run backtest for symbol', type=str, default=None)
        parser.add_argument('--start-date', help='Start date for backtest (YYYY-MM-DD)', type=str, default=None)
        parser.add_argument('--train-ml', help='Train ML models for all high-volume symbols', action='store_true')
        parser.add_argument('--generate-ml-report', help='Generate ML models analytics report', action='store_true')
        args = parser.parse_args()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        clean_old_cache()
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        await test_telegram()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        if args.backtest:
            if args.backtest == 'all':
                # Backtest all high volume pairs
                symbols = await load_markets()
                high_volume_symbols, _ = await filter_high_volume_symbols(symbols)
                
                for symbol in high_volume_symbols[:10]:  # limit to 10 symbols for demo
                    signals = await backtest_symbol(symbol, start_date=args.start_date)
                    if signals:
                        logger.info(f"Backtest {symbol}: {len(signals)} signals generated")
                    await asyncio.sleep(1)
            else:
                # Backtest specific symbol
                signals = await backtest_symbol(args.backtest, start_date=args.start_date)
                if signals:
                    logger.info(f"Backtest {args.backtest}: {len(signals)} signals generated")
            
            # Generate analytics after backtest
            generate_analytics()
            return
        
        # Train ML models if requested
        if args.train_ml:
            symbols = await load_markets()
            high_volume_symbols, _ = await filter_high_volume_symbols(symbols)
            logger.info(f"Starting batch ML training for {len(high_volume_symbols)} high-volume symbols")
            good_models = await batch_train_ml_models(high_volume_symbols)
            logger.info(f"Trained {len(good_models) if good_models else 0} good ML models")
            return
        
        # Generate ML report if requested
        if args.generate_ml_report:
            generate_ml_analytics_report()
            return
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
        while True:
            try:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä—ã–Ω–∫–æ–≤
                symbols = await load_markets()
                
                if not symbols:
                    logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–∏–º–≤–æ–ª—ã. –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ 5 –º–∏–Ω—É—Ç.")
                    await asyncio.sleep(300)
                    continue
                
                # –§–∏–ª—å—Ç—Ä –ø–æ –æ–±—ä—ë–º—É
                high_volume_symbols, volume_data = await filter_high_volume_symbols(symbols)
                
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(high_volume_symbols)} –ø–∞—Ä —Å –≤—ã—Å–æ–∫–∏–º –æ–±—ä—ë–º–æ–º")
                
                # –û–±—É—á–µ–Ω–∏–µ ML-–º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä —Å –≤—ã—Å–æ–∫–∏–º –æ–±—ä—ë–º–æ–º (–≤ —Ñ–æ–Ω–µ)
                if config['use_ml_predictions']:
                    asyncio.create_task(batch_train_ml_models(high_volume_symbols))
                    logger.info("–ó–∞–ø—É—â–µ–Ω–æ —Ñ–æ–Ω–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ ML-–º–æ–¥–µ–ª–µ–π")
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä –ø–∞—á–∫–∞–º–∏
                signals = []
                chunk_size = 10
                
                for i in range(0, len(high_volume_symbols), chunk_size):
                    chunk = high_volume_symbols[i:i + chunk_size]
                    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—á–∫–∏ {i//chunk_size + 1}/{len(high_volume_symbols) // chunk_size + 1}: {len(chunk)} –ø–∞—Ä")
                    
                    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—á–∫–∏
                    tasks = [process_pair(symbol, volume_data=volume_data) for symbol in chunk]
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    
                    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—à–∏–±–æ–∫ –∏ None –∑–Ω–∞—á–µ–Ω–∏–π
                    chunk_signals = [r for r in results if r is not None and not isinstance(r, Exception)]
                    signals.extend(chunk_signals)
                    
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ —Ç–µ–∫—É—â–µ–π –ø–∞—á–∫–µ: {len(chunk_signals)}")
                    await asyncio.sleep(5)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞—á–∫–∞–º–∏
                
                logger.info(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {len(signals)}")
                
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ ML-–º–æ–¥–µ–ª—è–º —Ä–∞–∑ –≤ –¥–µ–Ω—å
                if datetime.now().hour == 0 and datetime.now().minute < 15:
                    generate_ml_analytics_report()
                
                # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º —Ü–∏–∫–ª–æ–º
                logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ {60*5} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º...")
                await asyncio.sleep(60 * 5)  # 5 –º–∏–Ω—É—Ç –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
                await asyncio.sleep(60)

    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

async def update_excel():
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Excel-—Ñ–∞–π–ª–∞ —Å –∏—Å—Ç–æ—Ä–∏–µ–π —Å–∏–≥–Ω–∞–ª–æ–≤"""
    try:
        export_csv_to_excel()
        logger.debug("Excel-—Ñ–∞–π–ª –æ–±–Ω–æ–≤–ª–µ–Ω")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Excel: {e}")

def generate_ml_analytics_report():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ ML-–º–æ–¥–µ–ª–µ–π"""
    try:
        # Check if we have any models trained
        model_dir = 'models'
        os.makedirs(model_dir, exist_ok=True)
        
        if not os.listdir(model_dir):
            logger.warning("–ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö ML-–º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
            
        # Initialize workbook
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "ML Models Analysis"
        
        # Set headers
        headers = [
            "Symbol", "Model Type", "Accuracy", "Top Features", 
            "Signal Win Rate", "Total Signals", "Long Accuracy", "Short Accuracy",
            "Avg Confidence", "Last Trained"
        ]
        
        for col, header in enumerate(headers, 1):
            ws.cell(row=1, column=col, value=header)
            
        # Load signals from CSV to calculate win rates
        signals_df = None
        if os.path.exists('signals_history.csv'):
            try:
                signals_df = pd.read_csv('signals_history.csv')
                # Convert to proper types and handle missing values
                signals_df = signals_df.fillna('')
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ signals_history.csv: {e}")
                
        # Process each model
        row = 2
        for filename in os.listdir(model_dir):
            if filename.endswith('_model.pkl'):
                try:
                    # Parse model info from filename
                    parts = filename.replace('_model.pkl', '').split('_')
                    symbol = parts[0]
                    timeframe = parts[1] if len(parts) > 1 else '1h'
                    
                    # Load model and feature importance
                    model_path = os.path.join(model_dir, filename)
                    feature_path = os.path.join(model_dir, f"{symbol}_{timeframe}_feature_importance.pkl")
                    
                    if not os.path.exists(feature_path):
                        continue
                        
                    model = joblib.load(model_path)
                    feature_importance = joblib.load(feature_path)
                    
                    # Get top 3 features
                    top_features = sorted(
                        feature_importance.items(),
                        key=lambda x: x[1],
                        reverse=True
                    )[:3]
                    top_features_str = ", ".join([f"{f[0]} ({f[1]:.3f})" for f in top_features])
                    
                    # Get model last trained date
                    last_trained = datetime.fromtimestamp(os.path.getmtime(model_path)).strftime('%Y-%m-%d %H:%M')
                    
                    # Calculate signal accuracy using ML predictions
                    ml_accuracy = None
                    signals_count = 0
                    long_accuracy = None
                    short_accuracy = None
                    avg_confidence = None
                    
                    if signals_df is not None and 'ml_direction' in signals_df.columns:
                        # Filter signals with this symbol and ML predictions
                        symbol_signals = signals_df[signals_df['symbol'] == symbol]
                        symbol_signals = symbol_signals[symbol_signals['ml_direction'] != 'none']
                        
                        if len(symbol_signals) > 0:
                            signals_count = len(symbol_signals)
                            
                            # Count successful signals (those that hit TP)
                            successful = symbol_signals[symbol_signals['status'] == 'tp']
                            if len(successful) > 0:
                                ml_accuracy = len(successful) / signals_count
                                
                            # Long accuracy
                            long_signals = symbol_signals[symbol_signals['type'] == 'long']
                            if len(long_signals) > 0:
                                long_successful = long_signals[long_signals['status'] == 'tp']
                                long_accuracy = len(long_successful) / len(long_signals) if len(long_signals) > 0 else None
                                
                            # Short accuracy
                            short_signals = symbol_signals[symbol_signals['type'] == 'short']
                            if len(short_signals) > 0:
                                short_successful = short_signals[short_signals['status'] == 'tp']
                                short_accuracy = len(short_successful) / len(short_signals) if len(short_signals) > 0 else None
                                
                            # Average confidence
                            avg_confidence = symbol_signals['ml_confidence'].astype(float).mean() if 'ml_confidence' in symbol_signals.columns else None
                    
                    # Write to worksheet
                    ws.cell(row=row, column=1, value=symbol)
                    ws.cell(row=row, column=2, value="RandomForest")
                    
                    # Model accuracy (from cross-validation)
                    model_accuracy = getattr(model, 'oob_score_', None)
                    if model_accuracy is None and hasattr(model, 'oob_score'):
                        model_accuracy = model.oob_score
                    ws.cell(row=row, column=3, value=model_accuracy if model_accuracy is not None else "N/A")
                    
                    ws.cell(row=row, column=4, value=top_features_str)
                    ws.cell(row=row, column=5, value=ml_accuracy if ml_accuracy is not None else "N/A")
                    ws.cell(row=row, column=6, value=signals_count)
                    ws.cell(row=row, column=7, value=long_accuracy if long_accuracy is not None else "N/A")
                    ws.cell(row=row, column=8, value=short_accuracy if short_accuracy is not None else "N/A")
                    ws.cell(row=row, column=9, value=avg_confidence if avg_confidence is not None else "N/A")
                    ws.cell(row=row, column=10, value=last_trained)
                    
                    row += 1
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –º–æ–¥–µ–ª–∏ {filename}: {e}")
                    
        # Adjust column widths
        for col in range(1, len(headers) + 1):
            ws.column_dimensions[get_column_letter(col)].width = 15
            
        # Save workbook
        wb.save("ml_analytics_report.xlsx")
        logger.info("–û—Ç—á–µ—Ç –ø–æ ML-–º–æ–¥–µ–ª—è–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: ml_analytics_report.xlsx")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞ –ø–æ ML-–º–æ–¥–µ–ª—è–º: {e}")

# –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")